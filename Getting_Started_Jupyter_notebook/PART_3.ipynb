{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III - Building a Flare Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posts in ​ r/india can be corresponding to multiple topics. Each post is tagged for filtering purposes. These tags are called a flares in the reddit world. ​ r/india has flairs like Politics,AskIndia, Science/Technology etc.\n",
    "\n",
    "To build a classifier which can predict the flare of a reddit post, Using data collected in Part I as training and validation data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gargi/anaconda2/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('sample_update_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Dependent and independent variables\n",
    "y = data.flair\n",
    "X = data.feature_combine\n",
    "print(int(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.09,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy 0.5092592592592593\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.45      1.00      0.62         9\n",
      "     Non-Political       0.50      0.17      0.25        12\n",
      "     [R]eddiquette       0.50      0.20      0.29         5\n",
      "         Scheduled       0.33      0.17      0.22         6\n",
      "       Photography       0.50      0.08      0.13        13\n",
      "Science/Technology       0.88      0.78      0.82         9\n",
      "          Politics       0.33      0.11      0.17         9\n",
      "  Business/Finance       0.32      0.86      0.46         7\n",
      "    Policy/Economy       0.56      1.00      0.71        15\n",
      "            Sports       1.00      0.22      0.36         9\n",
      "              Food       1.00      0.71      0.83         7\n",
      "               AMA       0.38      0.71      0.50         7\n",
      "\n",
      "          accuracy                           0.51       108\n",
      "         macro avg       0.56      0.50      0.45       108\n",
      "      weighted avg       0.57      0.51      0.45       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = nb.fit(X_train, y_train)\n",
    "#pickle.dump(NB,open(\"model_NB.sav\",'wb'))\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"NB accuracy {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy % 0.6574074074074074\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.69      1.00      0.82         9\n",
      "     Non-Political       0.50      0.33      0.40        12\n",
      "     [R]eddiquette       0.43      0.60      0.50         5\n",
      "         Scheduled       0.62      0.83      0.71         6\n",
      "       Photography       0.60      0.23      0.33        13\n",
      "Science/Technology       0.69      1.00      0.82         9\n",
      "          Politics       0.75      0.33      0.46         9\n",
      "  Business/Finance       0.33      0.86      0.48         7\n",
      "    Policy/Economy       0.88      1.00      0.94        15\n",
      "            Sports       1.00      0.56      0.71         9\n",
      "              Food       1.00      0.86      0.92         7\n",
      "               AMA       0.75      0.43      0.55         7\n",
      "\n",
      "          accuracy                           0.66       108\n",
      "         macro avg       0.69      0.67      0.64       108\n",
      "      weighted avg       0.70      0.66      0.64       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "SGD = sgd.fit(X_train, y_train)\n",
    "#pickle.dump(SGD,open(\"model_SGC.sav\",'wb'))\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"SGD accuracy % {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1,max_iter=1300, C=1e5)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy % 0.6851851851851852\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.90      1.00      0.95         9\n",
      "     Non-Political       0.43      0.25      0.32        12\n",
      "     [R]eddiquette       0.44      0.80      0.57         5\n",
      "         Scheduled       0.67      0.67      0.67         6\n",
      "       Photography       0.45      0.38      0.42        13\n",
      "Science/Technology       0.80      0.89      0.84         9\n",
      "          Politics       0.83      0.56      0.67         9\n",
      "  Business/Finance       0.45      0.71      0.56         7\n",
      "    Policy/Economy       0.94      1.00      0.97        15\n",
      "            Sports       0.86      0.67      0.75         9\n",
      "              Food       0.86      0.86      0.86         7\n",
      "               AMA       0.50      0.57      0.53         7\n",
      "\n",
      "          accuracy                           0.69       108\n",
      "         macro avg       0.68      0.70      0.67       108\n",
      "      weighted avg       0.69      0.69      0.68       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LOGREG = logreg.fit(X_train, y_train)\n",
    "#pickle.dump(LOGREG,open(\"model_LOGREG.sav\",'wb'))\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(f\"LOG accuracy % {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM accuracy % 0.6018518518518519\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.90      1.00      0.95         9\n",
      "     Non-Political       0.67      0.50      0.57        12\n",
      "     [R]eddiquette       0.33      0.40      0.36         5\n",
      "         Scheduled       0.60      0.50      0.55         6\n",
      "       Photography       0.67      0.15      0.25        13\n",
      "Science/Technology       0.57      0.89      0.70         9\n",
      "          Politics       0.50      0.33      0.40         9\n",
      "  Business/Finance       0.33      0.71      0.45         7\n",
      "    Policy/Economy       0.94      1.00      0.97        15\n",
      "            Sports       0.40      0.44      0.42         9\n",
      "              Food       0.58      1.00      0.74         7\n",
      "               AMA       0.50      0.14      0.22         7\n",
      "\n",
      "          accuracy                           0.60       108\n",
      "         macro avg       0.58      0.59      0.55       108\n",
      "      weighted avg       0.62      0.60      0.57       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                  ])\n",
    "RM = ranfor.fit(X_train, y_train)\n",
    "#pickle.dump(RM,open(\"model_RM.sav\",'wb'))\n",
    "y_pred = ranfor.predict(X_test)\n",
    "\n",
    "print(f\"RM accuracy % {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy % 0.5916666666666667\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.91      1.00      0.95        10\n",
      "     Non-Political       0.25      0.42      0.31        12\n",
      "     [R]eddiquette       0.40      0.33      0.36         6\n",
      "         Scheduled       0.62      0.71      0.67         7\n",
      "       Photography       0.00      0.00      0.00        16\n",
      "Science/Technology       0.82      1.00      0.90         9\n",
      "          Politics       0.56      0.50      0.53        10\n",
      "  Business/Finance       0.67      0.25      0.36         8\n",
      "    Policy/Economy       1.00      0.94      0.97        16\n",
      "            Sports       1.00      0.44      0.62         9\n",
      "              Food       1.00      0.78      0.88         9\n",
      "               AMA       0.27      0.88      0.41         8\n",
      "\n",
      "          accuracy                           0.59       120\n",
      "         macro avg       0.62      0.60      0.58       120\n",
      "      weighted avg       0.61      0.59      0.57       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#mlp\n",
    "mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                 ])\n",
    "MLP = mlp.fit(X_train, y_train)\n",
    "#pickle.dump(MLP,open(\"model_MLP.sav\",'wb'))\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(f\"MLP accuracy % {accuracy_score(y_pred, y_test)}\")\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/gargi/anaconda2/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (1.18.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/gargi/anaconda2/lib/python3.8/site-packages (from keras) (1.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_posts = data.feature_combine\n",
    "train_tags = data.flair\n",
    "\n",
    "test_posts = train_posts[540:]\n",
    "test_tags = train_tags[540:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 120 samples\n",
      "Epoch 1/2\n",
      "1080/1080 [==============================] - 1s 512us/step - loss: 2.0771 - accuracy: 0.3130 - val_loss: 10.0841 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1080/1080 [==============================] - 0s 360us/step - loss: 1.2775 - accuracy: 0.6815 - val_loss: 15.1580 - val_accuracy: 0.0167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_words = 1200\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 0s 104us/step\n",
      "Test accuracy: 0.668181836605072\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
